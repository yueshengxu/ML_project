{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from layers import GraphConvolution\n",
    "\n",
    "\n",
    "class GCN(nn.Module):\n",
    "    def __init__(self, nfeat, nhid, nclass, dropout):\n",
    "        super(GCN, self).__init__()\n",
    "        self.nfeat = nfeat\n",
    "        self.gc1 = GraphConvolution(nfeat, nhid)\n",
    "        self.gc2 = GraphConvolution(nhid, nclass)\n",
    "        self.dropout = dropout\n",
    "        self.linear_r = nn.Linear(5, nfeat)\n",
    "        self.linear_p = nn.Linear(6, nfeat)\n",
    "        self.linear_u = nn.Linear(7, nfeat)\n",
    "        self.linear_y = nn.Linear(2, 2)\n",
    "        self.linear_a = nn.Linear(2, 2)\n",
    "        \n",
    "    def forward(self, inputx, adj, nums):\n",
    "        x = torch.zeros(len(inputx),self.nfeat)\n",
    "        x = x.cuda()\n",
    "        # review\n",
    "        x[:nums[0][0]] = self.linear_r(torch.cuda.FloatTensor(inputx[:nums[0][0]]))\n",
    "        # user\n",
    "        x[nums[0][0]:nums[0][1]] = self.linear_u(torch.cuda.FloatTensor(inputx[nums[0][0]:nums[0][1]]))\n",
    "\n",
    "        if nums[1][0] != nums[1][1]:\n",
    "            x[nums[0][1]:nums[1][0]] = self.linear_r(torch.cuda.FloatTensor(inputx[nums[0][1]:nums[1][0]]))\n",
    "            x[nums[1][0]:nums[1][1]] = self.linear_u(torch.cuda.FloatTensor(inputx[nums[1][0]:nums[1][1]]))\n",
    "        if nums[2][0] != nums[2][1]:\n",
    "            x[nums[1][1]:nums[2][0]] = self.linear_r(torch.cuda.FloatTensor(inputx[nums[1][1]:nums[2][0]]))\n",
    "            x[nums[2][0]:nums[2][1]] = self.linear_u(torch.cuda.FloatTensor(inputx[nums[2][0]:nums[2][1]]))\n",
    "        # product\n",
    "        x[nums[2][1]:] = self.linear_p(torch.cuda.FloatTensor(inputx[nums[2][1]:]))\n",
    "        x = F.relu(self.gc1(x, adj))\n",
    "        # x = F.dropout(x, self.dropout, training=self.training)\n",
    "        x = self.gc2(x, adj)\n",
    "\n",
    "        out = self.linear_y(x)\n",
    "        a = self.linear_a(x)\n",
    "        return x,F.log_softmax(x, dim=1),torch.sigmoid(out),torch.sigmoid(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DCG_score(logit, labels):\n",
    "    #Sorting based on the value of \"scores\"\n",
    "    d = {\"scores\":logit.cpu().detach().numpy(),\"labels\":labels.cpu().detach().numpy()}\n",
    "    df = pd.DataFrame(d)\n",
    "    df = df.sort_values(\"scores\", ascending=False)    \n",
    "    #reset index so that index is now reflecting the rank.\n",
    "    df.reset_index(inplace=True,drop=True)\n",
    "    r = df[df['labels']==1].index\n",
    "    return sum(1/np.log2(2+r))\n",
    "    \n",
    "def max_DCG_score(num_spam):\n",
    "    # rank all spams at the top\n",
    "    r = list(range(2,2+num_spam))     #list of (spammers'ranks+2) \n",
    "    z = sum(1/np.log2(r))             \n",
    "    return z\n",
    "\n",
    "def NDCG_score(maxDCG, pos_group_idx, neg_group_idx, logit):\n",
    "    num_total_sample = len(pos_group_idx) * int(0.1*len(neg_group_idx))\n",
    "    subsample_idx = np.random.choice(neg_group_idx, num_total_sample)\n",
    "    neg_subsample_logit = logit[subsample_idx].reshape((len(pos_group_idx), int(0.1*len(neg_group_idx))))\n",
    "    pos_logit = logit[pos_group_idx].reshape((-1, 1))\n",
    "    gap_logit = 1/(1+torch.exp(pos_logit - neg_subsample_logit))\n",
    "    total_r = torch.sum(gap_logit, 1)\n",
    "    total_dcg_score = (1/torch.log2(2+total_r))/(1/np.log2(2))\n",
    "    dcg_score = torch.sum(total_dcg_score)/len(pos_group_idx)\n",
    "    return dcg_score\n",
    "\n",
    "def construct_comparison_matrix(g,k):\n",
    "    # vectorization\n",
    "    # for each positive node, sample k negative nodes\n",
    "    positive_indices = [i for i, x in enumerate(g) if x == 1]    \n",
    "    negative_indices = [i for i, x in enumerate(g) if x == 0] \n",
    "    comparison_matrix = []\n",
    "    for i in positive_indices:\n",
    "        arr = rand.sample(negative_indices, k)\n",
    "        arr.insert(0,i)\n",
    "        comparison_matrix.append(arr)\n",
    "    return np.asarray(comparison_matrix).astype(int)\n",
    "\n",
    "\n",
    "def construct_group_comparison_matrix(comparison_type, group0_index, group1_index,g,k):\n",
    "\n",
    "    if   (comparison_type==\"4vs2\"):\n",
    "        positive_indices = [i for i, x in enumerate(g[group1_index]) if x == 1] \n",
    "        negative_indices = [i for i, x in enumerate(g[group1_index]) if x == 0] \n",
    "    elif (comparison_type==\"3vs1\"):\n",
    "        positive_indices = [i for i, x in enumerate(g[group0_index]) if x == 1] \n",
    "        negative_indices = [i for i, x in enumerate(g[group0_index]) if x == 0] \n",
    "    elif (comparison_type==\"3vs2\"):\n",
    "        positive_indices = [i for i, x in enumerate(g[group0_index]) if x == 1] \n",
    "        negative_indices = [i for i, x in enumerate(g[group1_index]) if x == 0] \n",
    "    elif (comparison_type==\"4vs1\"):    \n",
    "        positive_indices = [i for i, x in enumerate(g[group1_index]) if x == 1] \n",
    "        negative_indices = [i for i, x in enumerate(g[group0_index]) if x == 0] \n",
    "    comparison_matrix = []\n",
    "    for i in positive_indices:\n",
    "        arr = rand.sample(negative_indices, k)\n",
    "        arr.insert(0,i)\n",
    "        comparison_matrix.append(arr)\n",
    "    return np.asarray(comparison_matrix).astype(int)\n",
    "\n",
    "def construct_difference_matrix(k):\n",
    "    d = torch.diag(-1*torch.ones(k))\n",
    "    first_col = torch.ones(k,1)\n",
    "    difference_matrix = torch.cat((first_col,d),1)\n",
    "    return difference_matrix\n",
    "\n",
    "def avg_ranking_loss(comparison_matrix,difference_matrix,s):\n",
    "    S = s[comparison_matrix].t()\n",
    "    k, n = S.shape\n",
    "    k = k -1  # exclude the first column\n",
    "    return torch.sum(torch.log(1+torch.exp((torch.mm(-1*difference_matrix,S)))))/(k*n)\n",
    "\n",
    "def vectorized_ndcg_score(comparison_matrix,difference_matrix,s,z):\n",
    "    S = s[comparison_matrix].t()\n",
    "    return torch.sum(1/torch.log2(2+torch.sum(1/(1+torch.exp(torch.mm(difference_matrix,S))),dim=0)))/z\n",
    "\n",
    "def fairness_loss1(logit, maxDCG_g1, maxDCG_g0, pos_group1_idx, pos_group0_idx, neg_group1_idx, neg_group0_idx):\n",
    "    xNDCG_group0 = NDCG_score(maxDCG_g0, pos_group0_idx, neg_group0_idx, logit)\n",
    "    xNDCG_group1 = NDCG_score(maxDCG_g1, pos_group1_idx, neg_group1_idx, logit)\n",
    "\n",
    "    return xNDCG_group0, xNDCG_group1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import argparse\n",
    "import numpy as np\n",
    "import pickle\n",
    "import scipy.sparse as sp\n",
    "import random\n",
    "import os\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import csv\n",
    "import utils as U\n",
    "from GCN_models import GCN\n",
    "from sklearn import metrics\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from tqdm import tqdm\n",
    "from ndcg_score import *\n",
    "from di import *\n",
    "import csv_util\n",
    "\n",
    "device = torch.device('cuda:0')\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--epochs', type=int, default=50,)\n",
    "parser.add_argument('--data', nargs='*', default=['Chi'])\n",
    "parser.add_argument('--optimize', nargs='*', default=['ndcg'])\n",
    "\n",
    "args = parser.parse_args()\n",
    "\n",
    "class Parameters:\n",
    "    def __init__(self):\n",
    "        self.seed = 42\n",
    "        self.lr = 0.005\n",
    "        self.wd = 1e-3\n",
    "        self.hidden = 16\n",
    "        self.dropout = 0.5\n",
    "\n",
    "        self.train_ratio = 0.3\n",
    "        self.val_ratio = 0.2\n",
    "        self.test_ratio = 0.5\n",
    "        self.data_prefix = '../data/'\n",
    "        self.model_prefix = '../model/'\n",
    "        self.tensorboard = True\n",
    "        self.setting = 'fairness_NDCG'\n",
    "\n",
    "\n",
    "class GCNModel:\n",
    "    def __init__(self, parameters):\n",
    "        self._param = parameters\n",
    "        self.train_domain = self._param.train_domain\n",
    "\n",
    "        self.list_idx = None\n",
    "        self.features = None\n",
    "        self.labels = None\n",
    "        self.user_ground_truth = None\n",
    "        self.nums = None\n",
    "        self.rev_nums = None\n",
    "        self.adj = None\n",
    "\n",
    "        self.idx_train = None\n",
    "        self.idx_train_rev = None\n",
    "        self.idx_val = None\n",
    "        self.idx_test = None\n",
    "        self.idx_whole = None\n",
    "\n",
    "        self.group0_train_idx = None\n",
    "        self.group0_test_idx = None\n",
    "        self.group1_train_idx = None\n",
    "        self.group1_test_idx = None\n",
    "\n",
    "        self.group0_train_idx_tensor = None\n",
    "        self.group1_train_idx_tensor = None\n",
    "        self.group0_test_idx_tensor = None\n",
    "        self.group1_test_idx_tensor = None\n",
    "\n",
    "\n",
    "        self.setup_seed()\n",
    "        self.load_data()\n",
    "        self.GCN, self.optimizer = self.build_GCN_model()\n",
    "        if self._param.tensorboard:\n",
    "            self.writer = SummaryWriter(comment='fairGCN/{0}_{1}{2}{3}_{4}_lr_{5}'.format(self._param.train_domain,\n",
    "                                                                                          self._param.train_ratio,\n",
    "                                                                                          self._param.val_ratio,\n",
    "                                                                                          self._param.test_ratio,\n",
    "                                                                                          self._param.setting,\n",
    "                                                                                          self._param.lr))\n",
    "\n",
    "\n",
    "    def setup_seed(self):\n",
    "        torch.manual_seed(self._param.seed)\n",
    "        torch.cuda.manual_seed_all(self._param.seed)\n",
    "        np.random.seed(self._param.seed)\n",
    "        random.seed(self._param.seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "\n",
    "\n",
    "    def load_data(self):\n",
    "        raw_features = U.read_pickle(self._param.data_prefix+self.train_domain+'_features.pickle')\n",
    "        review_ground_truth = U.read_pickle(self._param.data_prefix+'ground_truth_'+self.train_domain)\n",
    "        messages = U.read_pickle(self._param.data_prefix+'messages_'+self.train_domain)\n",
    "        review_group = U.read_pickle(self._param.data_prefix+'review_groups_by_user_'+self.train_domain+'.pkl')\n",
    "\n",
    "        print('read data...')\n",
    "        train_rev = U.read_data('train', 'review', self.train_domain, self._param.train_ratio, self._param.val_ratio)\n",
    "        val_rev = U.read_data('val', 'review', self.train_domain, self._param.train_ratio, self._param.val_ratio)\n",
    "        test_rev = U.read_data('test', 'review', self.train_domain, self._param.train_ratio, self._param.val_ratio)\n",
    "        self.rev_nums = len(train_rev) + len(val_rev) + len(test_rev)\n",
    "\n",
    "        print('read user product')\n",
    "        train_user, train_prod = U.read_user_prod(train_rev)\n",
    "        val_user, val_prod = U.read_user_prod(val_rev)\n",
    "        test_user, test_prod = U.read_user_prod(test_rev)\n",
    "\n",
    "        portion_train = train_rev + train_user\n",
    "        portion_val = val_rev + val_user\n",
    "        portion_test = test_rev + test_user\n",
    "\n",
    "        print('building feature matrix')\n",
    "        self.list_idx, self.features, self.nums = U.feature_matrix(raw_features, portion_train, portion_val, portion_test)\n",
    "\n",
    "        print('building label list')\n",
    "        self.labels, self.user_ground_truth = U.onehot_label(review_ground_truth, self.list_idx)\n",
    "\n",
    "        print('building adj matrix')\n",
    "        idx_map = {j: i for i, j in enumerate(self.list_idx)}\n",
    "        self.adj = U.construct_adj_matrix(review_ground_truth, idx_map, self.labels)\n",
    "        self.adj = U.normalize(self.adj + sp.eye(self.adj.shape[0]))\n",
    "        self.adj = U.sparse_mx_to_torch_sparse_tensor(self.adj).cuda()\n",
    "\n",
    "        self.labels = torch.LongTensor(np.where(self.labels)[1]).cuda()\n",
    "\n",
    "        self.idx_train = torch.LongTensor(range(self.nums[-1][0])).cuda()\n",
    "        self.idx_train_rev = torch.LongTensor(range(self.nums[0][0])).cuda()\n",
    "        self.idx_val = torch.LongTensor(range(self.nums[-1][0], self.nums[-1][1])).cuda()\n",
    "        self.idx_test = torch.LongTensor(range(self.nums[-1][1], self.nums[-1][2])).cuda()\n",
    "        self.idx_test_rev = torch.LongTensor(range(self.nums[1][1], self.nums[2][0])).cuda()\n",
    "        self.idx_whole = torch.LongTensor(range(self.nums[-1][2])).cuda()\n",
    "\n",
    "        print('review group size: ', len(review_group))\n",
    "        self.find_group_idx(review_group, idx_map)\n",
    "\n",
    "\n",
    "\n",
    "    def find_group_idx(self, group_split_dict, idx_list):\n",
    "        group0_idx = []\n",
    "        group1_idx = []\n",
    "        for rid, gid in group_split_dict.items():\n",
    "            new_rid = ('u' + rid[0], 'p' + rid[1])\n",
    "            if gid == 1:\n",
    "                group1_idx.append(idx_list[new_rid])\n",
    "            elif gid == 0:\n",
    "                group0_idx.append(idx_list[new_rid])\n",
    "        assert len(group1_idx) + len(group0_idx) == self.rev_nums\n",
    "\n",
    "        # split group0 group1 as train and test set group0:\n",
    "        self.group0_train_idx = list(set(self.idx_train.tolist()).intersection(set(group0_idx)))\n",
    "        self.group0_test_idx = list(set(self.idx_test.tolist()).intersection(set(group0_idx)))\n",
    "        self.group1_train_idx = list(set(self.idx_train.tolist()).intersection(set(group1_idx)))\n",
    "        self.group1_test_idx = list(set(self.idx_test.tolist()).intersection(set(group1_idx)))\n",
    "\n",
    "        self.group0_train_idx_tensor = torch.LongTensor(self.group0_train_idx).cuda()\n",
    "        self.group1_train_idx_tensor = torch.LongTensor(self.group1_train_idx).cuda()\n",
    "        self.group0_test_idx_tensor = torch.LongTensor(self.group0_test_idx).cuda()\n",
    "        self.group1_test_idx_tensor = torch.LongTensor(self.group1_test_idx).cuda()\n",
    "\n",
    "\n",
    "        if os.path.exists(\"./group_gt/\"+str(self.train_domain)+\"_group_ground_truth.pickle\"):\n",
    "            print(\"File already exists\")\n",
    "        self.construct_group_truth_dict(self.train_domain)\n",
    "        if self.train_domain == 'Zip':\n",
    "            self.group1_train_idx = np.random.choice(self.group1_train_idx, int(0.5 * len(self.group1_train_idx)), replace=False)\n",
    "            self.sampled_group1_test_idx = np.random.choice(self.group1_test_idx, int(0.5 * len(self.group1_test_idx)), replace=False)\n",
    "\n",
    "        print('group 0 : {0}, group 1: {1}'.format(len(group0_idx), len(group1_idx)))\n",
    "        # return torch.tensor(group0_idx), torch.tensor(group1_idx)\n",
    "\n",
    "    def split_review(self):\n",
    "        # split reviews as group1 and group0 pos and neg\n",
    "        self.pos_g0_train, self.neg_g0_train = U.split_reviewer_nodes(self.group0_train_idx, self.labels)\n",
    "        self.pos_g0_test, self.neg_g0_test = U.split_reviewer_nodes(self.group0_test_idx, self.labels)\n",
    "        self.pos_g1_train, self.neg_g1_train = U.split_reviewer_nodes(self.group1_train_idx, self.labels)\n",
    "        self.pos_g1_test, self.neg_g1_test = U.split_reviewer_nodes(self.group1_test_idx, self.labels)\n",
    "        if self.train_domain == 'Zip':\n",
    "            self.sampled_pos_g1_test, self.sampled_neg_g1_test = U.split_reviewer_nodes(self.sampled_group1_test_idx, self.labels)\n",
    "\n",
    "        pos_train_rev, _ = U.split_reviewer_nodes(self.idx_train_rev, self.labels)\n",
    "        pos_test_rev, _ = U.split_reviewer_nodes(self.idx_test_rev, self.labels)\n",
    "\n",
    "        # max DCG score on train and test g1 and g0\n",
    "        self.maxDCG_g1_train = max_DCG_score(len(self.pos_g1_train))\n",
    "        self.maxDCG_g0_train = max_DCG_score(len(self.pos_g0_train))\n",
    "        self.maxDCG_g1_test = max_DCG_score(len(self.pos_g1_test))\n",
    "        self.maxDCG_g0_test = max_DCG_score(len(self.pos_g0_test))\n",
    "\n",
    "        self.maxDCG_train = max_DCG_score(len(pos_train_rev))\n",
    "        self.maxDCG_test = max_DCG_score(len(pos_test_rev))\n",
    "\n",
    "        print('maxDCG on group1 train: {0}, test: {1}'.format(self.maxDCG_g1_train, self.maxDCG_g1_test))\n",
    "        print('maxDCG on group0 train: {0}, test: {1}'.format(self.maxDCG_g0_train, self.maxDCG_g0_test))\n",
    "        print('maxDCG on train review: {0}, test review: {1}'.format(self.maxDCG_train, self.maxDCG_test))\n",
    "\n",
    "    def print_data(self):\n",
    "        print(\"index_train\", self.idx_train.size())\n",
    "        print(\"index_train_rev\", self.idx_train_rev.size())\n",
    "        print(\"group0_train_idx\", len(self.group0_train_idx))\n",
    "        print(\"group1_train_idx\", len(self.group1_train_idx))\n",
    "\n",
    "    def build_GCN_model(self):\n",
    "        model = GCN(nfeat=32,nhid=self._param.hidden, nclass=self.labels.max().item()+1, dropout=self._param.dropout)\n",
    "        optimizer = optim.Adam(model.parameters(), lr=self._param.lr, weight_decay=self._param.wd)\n",
    "        return model.cuda(), optimizer\n",
    "\n",
    "\n",
    "\n",
    "    def train(self, epoch, K, difference_matrix, loss_type):\n",
    "        self.GCN.train()\n",
    "        self.optimizer.zero_grad()\n",
    "        self.GCN.zero_grad()\n",
    "        logit, log_softmax , y_pred, group_pred = self.GCN(self.features, self.adj, self.nums)\n",
    "        comparison_matrix = construct_comparison_matrix(self.labels[self.idx_train_rev], K)\n",
    "        ndcg_loss = avg_ranking_loss(comparison_matrix, difference_matrix, logit[self.idx_train_rev][:, 1])\n",
    "\n",
    "\n",
    "        out_arr = []\n",
    "        xNDCG_group0, xNDCG_group1 = fairness_loss1(logit[:, 1], self.maxDCG_g1_train, self.maxDCG_g0_train, self.pos_g1_train, self.pos_g0_train, self.neg_g1_train, self.neg_g0_train)\n",
    "        fairness_loss = torch.maximum(xNDCG_group1/xNDCG_group0,xNDCG_group0/xNDCG_group1)\n",
    "        print(ndcg_loss)\n",
    "        print(fairness_loss)\n",
    "        print(\"------------------------------------------\")\n",
    "        out_arr.append(ndcg_loss.cpu().detach())\n",
    "        out_arr.append(fairness_loss.cpu().detach())\n",
    "        \n",
    "        loss = ndcg_loss - 5*fairness_loss\n",
    "        loss.backward()\n",
    "\n",
    "        self.optimizer.step()\n",
    "        with torch.no_grad():\n",
    "            self.GCN.zero_grad()\n",
    "            logit, log_softmax , y_pred, group_pred = self.GCN(self.features, self.adj, self.nums)\n",
    "            true_NDCG = DCG_score(logit[self.idx_train_rev][:,1], self.labels[self.idx_train_rev])/self.maxDCG_train\n",
    "            true_NDCG_group1 = DCG_score(logit[self.group1_train_idx][:, 1], self.labels[self.group1_train_idx])/self.maxDCG_g1_train\n",
    "            true_NDCG_group0 = DCG_score(logit[self.group0_train_idx][:, 1], self.labels[self.group0_train_idx])/self.maxDCG_g0_train\n",
    "            out_arr.append(true_NDCG)\n",
    "            out_arr.append(true_NDCG_group1)\n",
    "            out_arr.append(true_NDCG_group0)\n",
    "            print(true_NDCG,true_NDCG_group1,true_NDCG_group0)\n",
    "        return out_arr\n",
    "        \n",
    "\n",
    "\n",
    "    def test(self, epoch, loss_type, difference_matrix):\n",
    "        self.GCN.eval()\n",
    "        loss_dict = dict()\n",
    "        loss = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            logit, output, y_pred, group_pred = self.GCN(self.features, self.adj, self.nums)\n",
    "        true_NDCG = DCG_score(logit[self.idx_test_rev][:, 1], self.labels[self.idx_test_rev])/self.maxDCG_test\n",
    "        true_NDCG_group0 = DCG_score(logit[self.group0_test_idx][:, 1], self.labels[self.group0_test_idx])/self.maxDCG_g0_test\n",
    "        true_NDCG_group1 = DCG_score(logit[self.group1_test_idx][:, 1], self.labels[self.group1_test_idx])/self.maxDCG_g1_test\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "        out_arr = []\n",
    "        out_arr.append(true_NDCG)\n",
    "        out_arr.append(true_NDCG_group0)\n",
    "        out_arr.append(true_NDCG_group1)\n",
    "        print(\"TEST:          \", true_NDCG,true_NDCG_group0,true_NDCG_group1)\n",
    "        return out_arr\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "    def main(self, loss_type):\n",
    "        output_list = []\n",
    "\n",
    "\n",
    "        difference_matrix = construct_difference_matrix(300).cuda()\n",
    "        self.split_review()     # get different node group high-low, pos-neg\n",
    "        \n",
    "        print(\"Finish\")\n",
    "        out_tr = []\n",
    "        out_ts = []\n",
    "        for epoch in tqdm(range(args.epochs)):\n",
    "            \n",
    "            row = self.train(epoch, 300, difference_matrix, loss_type)\n",
    "            out_tr.append(row)\n",
    "            \n",
    "            if (epoch)%4 == 0:\n",
    "                row_ts = self.test(epoch, loss_type, difference_matrix)\n",
    "                out_ts.append(row_ts)\n",
    "        np.array(out_tr)\n",
    "        np.array(out_ts)\n",
    "        import pickle\n",
    "        #pickle.dump( out_tr, open( \"result_ratio5.pkl\", \"wb\" ) )\n",
    "        pickle.dump( out_ts, open( \"test_ratio.pkl\", \"wb\" ) )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    loss_type = args.optimize\n",
    "    domain = args.data\n",
    "\n",
    "    for d in domain:\n",
    "        myParam = Parameters()\n",
    "        myParam.train_domain = d\n",
    "        myParam.tensorboard = True\n",
    "        print('training domain: {0}'.format(myParam.train_domain))\n",
    "        print('optimize:', loss_type)\n",
    "        myFairGCN = GCNModel(myParam)\n",
    "        myFairGCN.main(loss_type=loss_type)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
